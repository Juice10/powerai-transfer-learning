{
    "metadata": {
        "kernelspec": {
            "name": "python3-spark20", 
            "display_name": "Python 3.5 (Experimental) with Spark 2.0", 
            "language": "python"
        }, 
        "language_info": {
            "version": "3.5.2", 
            "name": "python", 
            "mimetype": "text/x-python", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }, 
            "file_extension": ".py", 
            "nbconvert_exporter": "python"
        }
    }, 
    "cells": [
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "# TensorFlow for Poets\nThis jupyter notebook implementation is based on Google's [TensorFlow for Poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html) tutorial, and works very well in [the IBM Data Science Experience](https://datascience.ibm.com/). Please check out the original tutorial as it has much more information on what is going on.\n\nIf you are using the IBM Data Science Experience you don't need to install Docker and/or TensorFlow, the notebooks come with TensorFlow pre-installed to get you going quickly and easily."
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Retrieving the images\nBefore you start any training, you'll need a set of images to teach the network about the new classes you want to recognize. We've created an archive of creative-commons licensed flower photos to use initially.\n\nDownload the sample images:"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": "!curl -O http://download.tensorflow.org/example_images/flower_photos.tgz\n!tar xzf flower_photos.tgz"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "After downloading 218MB, you should now have a copy of the flower photos available in your working directory."
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## (Re)training Inception\nThe retrain script is part of the tensorflow repo, but it is not installed as part of the pip package. So you need to download it manually, to the current directory:"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": "!curl -O https://raw.githubusercontent.com/tensorflow/tensorflow/r1.1/tensorflow/examples/image_retraining/retrain.py\n"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "At this point, we have a trainer, we have data, so let's train! We will train the Inception v3 network.\n\nInception is a huge image classification model with millions of parameters that can differentiate a large number of kinds of images. We're only training the final layer of that network, so training will end in a reasonable amount of time."
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "Start your image retraining with one big command:"
        }, 
        {
            "metadata": {
                "scrolled": true
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": "!python retrain.py \\\n  --bottleneck_dir=bottlenecks \\\n  --how_many_training_steps=500 \\\n  --model_dir=inception \\\n  --summaries_dir=training_summaries/basic \\\n  --output_graph=retrained_graph.pb \\\n  --output_labels=retrained_labels.txt \\\n  --image_dir=flower_photos"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "This script downloads the pre-trained Inception v3 model, adds a new final layer, and trains that layer on the flower photos you've downloaded.\n\nImageNet was not trained on any of these flower species originally. However, the kinds of information that make it possible for ImageNet to differentiate among 1,000 classes are also useful for distinguishing other objects. By using this pre-trained network, we are using that information as input to the final classification layer that distinguishes our flower classes."
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Using the Retrained Model\nThe retraining script will write out a version of the Inception v3 network with a final layer retrained to your categories to tf_files/retrained_graph.pb and a text file containing the labels to tf_files/retrained_labels.txt.\n\nThese files are both in a format that the C++ and Python image classification examples can use, so you can start using your new model immediately.\n\n### Classifying an image\nHere is a Python script that loads your new graph file and predicts with it.\n\nWe'll create it as a file called label_image.py in the working directory."
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": "!curl -L https://goo.gl/3lTKZs > label_image.py"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "Now, run the Python file you created, first on a daisy:\n\n<small>(Image by Retinafunk)</small>"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": "display(Image(filename='flower_photos/daisy/21652746_cc379e0eea_m.jpg'))\n!python label_image.py flower_photos/daisy/21652746_cc379e0eea_m.jpg"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "And then on a rose:\n\n<small>(Image by Lori Branham)</small>"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": "display(Image(filename='flower_photos/roses/2414954629_3708a1a04d.jpg'))\n!python label_image.py flower_photos/roses/2414954629_3708a1a04d.jpg "
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "You will then see a list of flower labels, in most cases with the right flower on top (though each retrained model may be slightly different).\n\nYou might get results like this for a daisy photo:\n\n<code>```daisy (score = 0.99071)\nsunflowers (score = 0.00595)\ndandelion (score = 0.00252)\nroses (score = 0.00049)\ntulips (score = 0.00032)\n```</code>\n\nThis indicates a high confidence it is a daisy, and low confidence for any other label.\n\nYou can use `label_image.py` to choose any image file to classify, either from your downloaded collection, or new ones.\n\n"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Other steps\n\nSee the original tutorial for other steps you can take:\n\n* [Optional Step: Trying Other Hyperparameters](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#6)\n* [Optional Step: Training on Your Own Categories](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#7)"
        }
    ], 
    "nbformat_minor": 1, 
    "nbformat": 4
}